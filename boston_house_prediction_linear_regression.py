# -*- coding: utf-8 -*-
"""Boston House Prediction - Linear Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pAH-jc0aQB7Nb4UFdYiUgZZ821i01D6T
"""



#importing library
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Data collection

boston_data = pd.read_csv('/content/BostonHousing.csv')
# Check whether read_csv is successful or not
# Check data format loaded through read_csv
boston_data.head()

# Data wrangling

# Input or independent value
X = boston_data.iloc[:, :13]

# Output or dependent value
Y = boston_data["medv"]

# Data Analysis

# Find correlation between all available columns
corr = boston_data.corr()
# Find correlated data columns using heatmaps
sns.heatmap(corr)
plt.show()

# Columns which are having correlation +ve and above 0.9 are highly correlated to each other
# We can drop any of them since it will not impact on output

#Right now I am not dropping any column and trying to predict the output with all input data

# Splitting train test data

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.30, random_state=10)

#Model Instantiation and training the model

# model instantiation
linear_model = LinearRegression()

# fit the model with input and corresponding output data
linear_model.fit(x_train, y_train)

#Testing the model

predicted_house_price = linear_model.predict(x_test)
print("Predicted House Prices")
print(predicted_house_price)

predicted_dataframe = pd.DataFrame(
    {"Predicted_Prices": predicted_house_price, "Actual_Prices": y_test})
print("Predicted and Actual Price Data frame")
print(predicted_dataframe)

plt.scatter(y_test, predicted_house_price, color='green')
plt.show()

